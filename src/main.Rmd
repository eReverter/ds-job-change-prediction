---
title: "Assignment 2"
author: 'Enric Reverter & Gerard Pons'
date: "14/10/2021"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, eval=F}
knitr::opts_chunk$set(echo = TRUE)
```

Assumptions:
- Sample from incomplete dataset.
- Everyone in this dataset is currently working.


### Required libraries

```{r, eval=F}
## Data manipulation
library(tidyverse)
library(dplyr)
library(mice)
library(Hmisc)
## Statistics
library(lsr)
library(missMDA)
library(VIM)
library(chemometrics)
library(arules)
library(skimr)
library(car)
library(FactoMineR)
library(factoextra)
library(effects)
## Plots
library(ggplot2)
library(ggExtra)
library(ggthemes)
library(processx)
library(plotly)
library(cowplot)
library(gridExtra)
library(RColorBrewer)
theme_set(theme_bw())
## Set data path
setwd("..")
data_path = file.path(getwd(), "data")
plot_path = file.path(getwd(), "plots")
```


# Data Exploration

Load the dataset:
```{r}
df = read.csv(file.path(data_path, "jobs.csv"))
```

Sample from the original dataset:
```{r, eval=F}
data = read.csv(file.path(data_path, "aug_train.csv"))
set.seed(020198)
sample = sample(1:nrow(data), 5000)
df = data[sample,]
write.csv(df, file.path(data_path, "jobs.csv"), row.names = FALSE)
```

Skim over it:
```{r, eval=F}
head(df)
summary(df)
str(df)
```

Convert data types to the proper format:
```{r}
df = df %>%
  mutate(across(where(is.character), ~ na_if(., ""))) %>%
  mutate(across(where(is.character) | matches("target"), ~ as.factor(.)))
```

Detail of factors:
```{r, eval=F}
df %>%
  select(., where(is.factor)) %>%
  sapply(., table)
table(df$last_new_job)
```


### Missing Values

As it can be seen, the dataset contains a lot of missing values, in some cases even exceeding the 30% of values from an attribute. These high values conditioned the imputation methods, which was first done using logical methods. Moreover, there are observations with more than 50% of the variables as null, which have been decided to be eliminated.
```{r}
count_na = function(x) {sum(is.na(x))}
df = df %>%
  mutate(across(matches("company"), ~ as.character(.))) %>%
  mutate(across(matches("company"), ~ na_if(., "NA"))) %>%
  mutate(across(matches("company"), ~ as.factor(.))) %>%
  mutate(count_na = apply(., 1, count_na))
summary(df$count_na)
boxplot(df$count_na)
table(df$count_na)
```

Visualizing the missing values:
```{r}
library(reshape2)
ggplot_missing <- function(data){
  df2 <- data %>% is.na %>% melt

  ggplot(df2, aes(Var2, Var1, fill=value)) + 
    geom_raster() +
    theme_minimal() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
    scale_fill_grey(name="", labels=c("Present", "Missing")) +
    theme(axis.text.x  = element_text(angle=45, vjust=1, hjust=1)) + 
    labs(title = "Number of Missing Values Across the Data",
         x = "Variables",
         y = "Observations")
}

ggplot_missing(select(df, -c("count_na")))
```

Eliminating the observations with many NA's:
```{r}
df = df %>%
  filter(., count_na < 5) %>%
  select(., -c("count_na"))
```

The rules used for logically imputation where as follow, always assuming that everyone in the dataset is currently working, as the target is looking or not for a job change:

- If the education level is null but they are enrolled in university, the education is set to high school.
- If major discipline is not null, the education level should be at least graduate.
- If company information is missing, it is imputed with Unknown, as the number of missing values for company information exceeds 30%.
- If gender is missing, it is imputed with Unknown, as there are nearly 30% of missing values in gender.
- If Major_Discipline is null, it is imputed with Other if the education level is Graduate, Masters or PhD, and imputed to No Major otherwise.
- If Experience ,Last_New_Job and Company information are null, the experience is imputed to <1.

- If company type is known and company size is missing, it is left for imputation and vic eversa. If both are missing they are labeled as Unknown.

```{r}
df = df %>%
  mutate(f.enrolled = case_when(enrolled_university == "no_enrollment" ~ "No",
                                !is.na(enrolled_university) ~ "Yes"))
df = df %>%
  # Convert factors to strings in order to impute them
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  
  # Impute education level as mentioned above
  mutate(education_level = case_when(is.na(education_level) & f.enrolled == "Yes" ~ "High School",
                                     !is.na(major_discipline) & !(education_level %in% c("Graduate", "Masters", "Phd")) ~ "Graduate",
                                     TRUE ~ education_level)) %>%
  
  # Impute major_discipline as mentioned above
  mutate(major_discipline = case_when(is.na(major_discipline) & !(education_level %in% c("Graduate", "Masters", "Phd")) ~ "No Major",
                                      is.na(major_discipline) & education_level %in% c("Graduate", "Masters", "Phd") ~ "Other",
                                      TRUE ~ major_discipline)) %>%
  
  # Impute enrolled_university
  mutate(enrolled_university = case_when(is.na(enrolled_university) & education_level %in% c("Masters", "Phd") ~ "no_enrollment",
                                         TRUE ~ enrolled_university)) %>%
  
  # Impute experience
  mutate(experience = case_when(is.na(experience) & (is.na(last_new_job) & is.na(company_size) & is.na(company_type)) ~ "<1",
                                TRUE ~ experience)) %>%
  
  # Impute gender
  mutate(gender = case_when(is.na(gender) ~ "Other",
                            TRUE ~ gender)) %>%
  
  # Impute company
  mutate(company_size = case_when(is.na(company_size) & is.na(company_type) ~ "Unknown",
                                  TRUE ~ company_size)) %>%
  mutate(company_type = case_when(is.na(company_type) & company_size == "Unknown" ~ "Other",
                                  TRUE ~ company_type)) %>%
  
  # Convert back to factors    
  mutate(across(where(is.character), ~ as.factor(.))) %>%
  
  # Drop unused columns
  select(., -c("f.enrolled"))
```

Visualizing the logical imputation:
```{r}
ggplot_missing(df)
```

After the logical imputation, the NA values do not account for more than 2% in any of the categories, and it was decided to impute them with factorial analysis for mixed data. It must be noted that a new flag attribute ‘Imputed’ was created, in order to keep track of these imputed observations when modelling, as they could cause problems.

Indicator of rows which still have NA's:
```{r}
colSums(is.na(df))

imputed_indicator = function(x) {if(count_na(x)>0) {return(TRUE)} else {return(FALSE)}}

df = df %>%
  mutate(imputed = apply(., 1, imputed_indicator))
```

## FAMD IMPUTATION

Impute with FAMD method:
```{r}
res.famd = imputeFAMD(select(df, -c("target", "city", "enrollee_id", "imputed")))
```

As it can be seen, the class frequencies after imputation have been compared to the ones before it, and there is no notable change.
```{r}
round(prop.table(table(df$education_level))*100,1)
round(prop.table(table(res.famd$completeObs$education_level))*100,1)
round(prop.table(table(df$last_new_job))*100,1)
round(prop.table(table(res.famd$completeObs$last_new_job))*100,1)
round(prop.table(table(df$enrolled_university))*100,1)
round(prop.table(table(res.famd$completeObs$enrolled_university))*100,1)
summary(df$training_hours)
```

Store complete dataset:
```{r}
df = data.frame(res.famd$completeObs, select(df, c("target", "city", "enrollee_id", "imputed")))
```

Mutate strings after FAMD converted them into dummy:
```{r}
df = df %>%
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  mutate(gender = str_remove(gender, "gender_")) %>%
  mutate(major_discipline = str_remove(major_discipline, "major_discipline_")) %>%
  mutate(company_type = str_remove(company_type, "company_type_")) %>%
  mutate(experience = str_remove(experience, "experience_")) %>%
  mutate(last_new_job = str_remove(last_new_job, "last_new_job_")) %>%
  mutate(across(where(is.character), ~ as.factor(.)))
```
With the complete dataset, some new attributes have been created: a new numerical variable has been created from the factor experience and a new factor has been created from the variable of city development. In future steps, it will be decided which one is the most suitable for the modelling process. It must be noted that since company size had a lot of NA, it has not been converted into numerical.

Convert experience into a numerical variable:
```{r}
df = df %>%
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  mutate(n.experience = case_when(experience == "<1" ~ "0",
                                experience == ">20" ~ "25",
                                TRUE ~ experience)) %>%
  mutate(n.experience = as.integer(n.experience)) %>%
  mutate(across(where(is.character), ~ as.factor(.)))

summary(df$n.experience)
summary(df$experience)
```

Convert city development index into a categorical variable:
```{r}
groups = 5

df$f.city_development_index = as.ordered(cut2(df$city_development_index, g=groups, m=nrow(df)/groups))
table(df$f.city_development_index)
```

Write the dataset:
```{r, eval=F}
write.csv(df, file.path(data_path, "jobs_compl.csv"), row.names = FALSE)
```

### Visualizations

#### Barplots

Algu així va bé?
```{r}
df %>%
  group_by(gender, target) %>%
  summarise(n = n()) %>%
  ggplot(data=., aes(x=reorder(gender, -n), y=n, fill=target)) +
  geom_bar(position="stack", stat="identity") +
  scale_fill_brewer(palette = "Blues") +
  geom_text(aes(label=n), position = position_stack(vjust = 0.5), size=2.9) +
  labs(x="Gender",
         y="Count",
         fill="Target") #+
  #theme(legend.position="none")

# plist[[1]] = p
# ggsave(file=file.path(plot_path,"bar_transmission.png"), plot=p)
```

### Outlier treatment

Univariate outliers can not be seen in the dataset for the two numerical variables present. One could think that training_hours contains some outliers, as they are above the extreme threshold. However, they are not too extreme and all of them have a very plausible value, hence imputation would not be a good practice in this case.

```{r, eval=F}

# BOXPLOT CITY DEVELOPMENT

extreme_out = quantile(df$training_hours)[[4]]+3*IQR(df$training_hours)


ggplot(data = df, aes(x="", y=training_hours)) +
  geom_boxplot(width=0.5) +
  geom_hline(yintercept = extreme_out, color="red") +
  scale_y_continuous(labels=scales::comma) 
labs(title='Boxplot Training Hours',
     y="Training Hours") +
  # Do not show x axis
  theme(axis.text.x=element_blank(), axis.ticks.x = element_blank(), axis.line.x = element_blank(), axis.title.x=element_blank())

num_outliers = df %>%
  filter(., training_hours > extreme_out) %>%
  nrow()
num_outliers

outliers = df %>%
  filter(., training_hours > extreme_out)

prop.table(table(df$gender))
prop.table(table(outliers$gender))
prop.table(table(df$relevent_experience))
prop.table(table(outliers$relevent_experience))
prop.table(table(df$enrolled_university))
prop.table(table(outliers$enrolled_university))
prop.table(table(df$education_level))
prop.table(table(outliers$education_level))
prop.table(table(df$major_discipline))
prop.table(table(outliers$major_discipline))
prop.table(table(df$last_new_job))
prop.table(table(outliers$last_new_job))
```

# Modelization

Before starting with the model, it is interesting to describe the response variable. It can be seen that it is significantly associated with all the numerical and categorical variables, except for training_hours, which sits really close to the threshold. It is also worth noting that the variables which have been kept in purpose both in numerical and categorical form are the ones that have a more significant association, meaning that the future assessment of how to treat them will be of particular interest. Overall, what can be said is that in general people who want to change jobs tend to be from less developed cities, have less experience and lower education.

```{r}
cat = FactoMineR::catdes(df[,-c(13:15)], 12)
cat$test.chi2
cat$quanti.var
cat$category
cat$quanti
```

Before starting with the modelling, the data should be split into working and test datasets, so that the created model can be compared and assessed with data that it has not seen, hence limiting overfitting. The chosen splitting size was 75-25.
```{r}
library(caret)
set.seed(020198)
trainIndex = createDataPartition(df$target, p = 0.75, list = FALSE, times = 1)
train = df[trainIndex,]
test = df[-trainIndex,]
```

Inspect the null model:
```{r}
df = select(train, -c("city", "enrollee_id", "imputed"))
m0 = glm(target ~ 1, data=df, family=binomial)
summary(m0)
```

After computing the null model, it was assessed how to treat the attribute experience: as a factor or as a numerical variable. 

Regarding being numerical, polynomial transformations were applied to it. It was seen that the p-value for a third degree polynomial suggests that this transformation is not needed (this conclusion can only be drawn because the variables constructed by Poly function are orthogonal), hence only a second order polynomial was kept. Using deviance tests, the comparison with the normal variable and the transformed one yield significantly different models, and with a better performance for the transformed one.

```{r}
mnexp = glm(target ~ n.experience, data=df, family=binomial)
summary(mnexp)
mnexppoly3 = glm(target ~ poly(n.experience,3), data=df, family=binomial)
summary(mnexppoly3)
mnexppoly2 = glm(target ~ poly(n.experience,2), data=df, family=binomial)
summary(mnexppoly2)
anova(mnexp,mnexppoly2,test='Chisq')
```

Regarding treating it as a factor, as it has more than 20 categories, some collapses have been found to improve the model results:
-Collapsing by quantiles
-Collapsing the model logically in Entry Level, Junior Level, Mid Level, Senior Level and Chief Level, using some well defined year ranges for the Data Science field.
```{r}
entry_level = c('<1','1','2')
junior_level = c('3','4')
mid_level = c('5','6')
senior_level = c('7','8','9','10')
chief_level = c('11','12','13','14','15','16','17','18','19','20','>20')

df = df %>% 
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  mutate(collapsed_exp = case_when(experience %in% entry_level ~ "Entry Level",
                                experience %in% junior_level ~ "Junior Level",
                                experience %in% mid_level ~ "Mid Level",
                                experience %in% senior_level ~ "Senior Level",
                                experience %in% chief_level ~ "Chief Level",
                                TRUE ~ experience)) %>%
  mutate(across(where(is.character), ~ as.factor(.)))


groups = 5

df$collapsed_exp2 = as.ordered(cut2(df$n.experience, g=groups, m=nrow(df)/groups))
table(df$collapsed_exp)
table(df$collapsed_exp2)

```

Comparing both collapsed models, the collapsed by quantiles results in the best one.
```{r} 
mcexp = glm(target ~ experience, data=df, family=binomial)
summary(mcexp)

mcexpcol = glm(target ~ collapsed_exp, data=df, family=binomial)
mcexpcol2 = glm(target ~ collapsed_exp2, data=df, family=binomial)


# LIDIA
anova(mcexpcol2,mcexp,test='Chisq')
anova(mcexpcol, mcexpcol2, test='Chisq') 
anova(mcexpcol,mcexp,test='Chisq')

```

After getting the best numerical and categorical transformations for the variable, the models created with them were compared. As they are not nested models, the deviance test anova() can not be applied, and it was decided to use AIC instead. It can be clearly seen that the numerical treatment of the variable outperforms the categorical, hence is the one that will be used in the following models. 
```{r}
AIC(mcexp,mcexpcol,mnexppoly2,mnexp, mcexpcol2)
```

The same analysis can be done for the city development index (which will not be extensively reported). Even after performing the transformation suggested by the MarginalModelPlots, the discretized version of the city development index is much better.
```{r}
mncdi = glm(target ~ city_development_index, data=df, family=binomial); summary(mncdi) # Numerical
mfcdi = glm(target ~ f.city_development_index, data=df, family=binomial); summary(mfcdi) # Categorical (collapsed above)

AIC(mncdi, mfcdi)

# For the improved cdi^-0.5 - known from the marginal model plots
marginalModelPlots(mncdi)
mncdi_tr = glm(target ~ I(city_development_index^-0.5), data=df, family=binomial)
marginalModelPlots(mncdi_tr)

AIC(mncdi,mncdi_tr, mfcdi)

# Discretizing the transformed index

groups = 5

df$f.city_development_index_tr = as.ordered(cut2(df$city_development_index^-0.5, g=groups, m=nrow(df)/groups))
mfcdi_tr = glm(target ~ f.city_development_index_tr, data=df, family=binomial)
AIC(mfcdi, mfcdi_tr)
```

After having chosen the best variables to work with, the focus was firstly on the two numerical variables, whose models were compared with and without interactions. As it can be seen with the deviance test, adding training hours to the model, either as an interaction or just addition, does not yield a statistically different model, hence only the second order transformation to experience is kept.
```{r}
m1 = glm(target ~ training_hours, data=df, family=binomial)
m2 = glm(target ~ poly(n.experience,2), data=df, family=binomial)

m3 = glm(target ~ training_hours+poly(n.experience,2), data=df, family=binomial)
m4 = glm(target ~ training_hours*poly(n.experience,2), data=df, family=binomial)

# Gross effects
anova(m0,m1,test="Chisq")
anova(m0,m2,test="Chisq")

# Net effects
anova(m1,m3,test="Chisq")
anova(m2,m3,test="Chisq")

# Interaction effects
anova(m3,m4,test="Chisq")

AIC(m0, m1, m2, m3, m4) 
```

Assessing it with marginal model plots, no transformations are suggested, as it yields a perfect fit.
```{r}
marginalModelPlots(m2) 
```

After that, the additive effect of variables is explored by using a step function with AIC, to be more permissive. It results in suggesting the addition of 7 of the variables to the model, which is significantly different and much better than the previous best one. Also, multicollinearity was discarded by doing a vif test.
```{r}
df = select(df, -c("experience", "collapsed_exp", "collapsed_exp2", "city_development_index", "f.city_development_index_tr"))
m5 = glm(target ~ poly(n.experience,2) + ., data=df, family=binomial)
maic = step(m5)
vif(maic)
anova(m2,maic,test="Chisq")
AIC(m2,maic)
```

Mirem aquí si serveix d'alguna cosa col·lapsar company size?
---

# Additive step with company size uncollapsed and collapsed
```{r}
# According to OECD:
small_company = c('<10', '10/49')
medium_company = c('50-99','100-500')
large_company = c('500-999', '1000-4999','5000-9999','10000+')

aux = df %>% 
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  mutate(company_size = case_when(company_size %in% small_company ~ 'Small Company',
                                  company_size %in% medium_company ~ 'Medium Company',
                                  company_size %in% large_company ~ 'Large Company',
                                  TRUE ~ company_size)) %>%
  mutate(across(where(is.character), ~ as.factor(.)))

maux = glm(target ~ poly(n.experience,2) + ., data=aux, family=binomial)
maux = step(maux)
vif(maux)
AIC(maic, maux)
```
---

To check for interactions the step function was used again, but this time using the BIC criterion,  in order to be more restrictive. The BIC criterion removed all of the possible interactions, hence model resulting from the AIC step is the resulting one.
```{r}
mbic = step(m5 , scope = . ~ .^2, k = log(nrow(df)))
AIC(m2, maic, mbic)
```

## MODEL INTERPRETATION

The model formula is as follows:

logit($\pi$~ijklqr~)$= \eta + \beta$~1~$experience$+$\beta$~2~$experience^2+\delta training + \alpha$~i~+$\nu$~j~+$\kappa$~k~ +$\xi$~l~+$\psi$~q~+$\lambda$~r~ 

The reference level is someone with Relevant Experience, doing a full time course, graduate level, majoring in arts, working in a company of unknown size that has not change a job in the past 4 years, and living in a city of poor development.

Briefly, it can be seen that:
Regarding numerical attributes, the odds of a job change increase with the experience but decrease the more training hours someone has.
Regarding categorical, having no relevant experience increases the odds, people with a collage degree are the ones more prone to change job, whereas the ones with phd are the less prone, the less developed a city is the more likely are workers to want to change jobs. Regarding changing jobs, the less likely are people that have just started a new job or that have been working in the same job for a long time, and if inspecting company size, people who work at big corporations are the ones less likely to change jobs, whereas people who work at small companies are the ones more likely.     
```{r}
summary(maic)
```


### Model Diagnostics

The added variable plots, which can bee seen in the Annex, do not show any alarming behavior and the same can be said for the MarginalModelPlots. Regarding the residualPlots, there is no much to be said, as overall the behavior is acceptable.
```{r}
avPlots(maic)
marginalModelPlots(maic)
residualPlots(maic)
```

Studentized Residuals: Some outliers have been found in them. It can be seen that they are all people who want to change jobs, and contrary to the whole dataset, the vast majority of them are only high school graduates (hence no major).
```{r}
mb = maic
n = dim(df)[1]
p = mb$rank
res_mb = rstudent(mb)
cut_off = qt(0.995,n-p-1)

Boxplot(res_mb)
abline(h=cut_off,col=2)
abline(h=-cut_off,col=2)

nrow(df[which(abs(res_mb)>cut_off),])

aux = df[which(abs(res_mb)>cut_off),]
summary(aux)

# Li enxufo tots encara que mirant nom'es les variables utilizades en el model hauria de ser suficient entenc
prop.table(table(aux$gender)); prop.table(table(df$gender))
prop.table(table(aux$relevent_experience)); prop.table(table(df$relevent_experience))
prop.table(table(aux$enrolled_university)); prop.table(table(df$enrolled_university))
prop.table(table(aux$education_level)); prop.table(table(df$education_level))
prop.table(table(aux$major_discipline)); prop.table(table(df$major_discipline))
prop.table(table(aux$company_size)); prop.table(table(df$company_size))
prop.table(table(aux$company_type)); prop.table(table(df$company_type))
prop.table(table(aux$last_new_job)); prop.table(table(df$last_new_job))
prop.table(table(aux$training_hours)); prop.table(table(df$training_hours))
prop.table(table(aux$n.experience)); prop.table(table(df$n.experience))
prop.table(table(aux$f.city_development_index)); prop.table(table(df$f.city_development_index))
prop.table(table(aux$target)); prop.table(table(df$target))
```

Hat Values: The cut off for this assessment has been 4 times the mean,as the dataset can be considered big enough. Regarding the description of the observations that fall under the criterion, there is a large proportion of people with no experience and PhD in comparison with the full dataset. As the had values indicate the leverage, these outliers have not been removed, as the overall effect will be assessed with Cook's distance.
```{r}
hat = hatvalues(mb)
hat_cut = 4*p/n 

Boxplot(hat)
abline(h=hat_cut,col=2)

sum(hat>hat_cut)

aux = df[which(hat>hat_cut),]
summary(aux)
```

Cook's distance: For the Cook's distance criterion, a threshold had to be defined to match the need of our model. As before, it can be seen that the proportions for people with no experience and for the ones with a PhD increase.
```{r}
cook = cooks.distance(mb)
cook_cut = 4/(n-p) 
cook_cut = 0.003


Boxplot(cook)
abline(h=cook_cut)

nrow(df[which(cook>cook_cut),])

aux = df[which(cook>cook_cut),]
summary(aux)
```

Visualize it:
```{r}
influencePlot(mb)
```

### Reevaluate the model

The outliers detected with the Cook's distance method have been removed from the dataset, and the model has been reevaluated without those observations. 

```{r}
df = df[which(cook<cook_cut),]

mbest = glm(formula = target ~ poly(n.experience, 2) + relevent_experience + 
    enrolled_university + education_level + company_size + last_new_job + 
    training_hours + f.city_development_index, family = binomial, 
    data = df)

influencePlot(mbest)
cook = cooks.distance(mbest)
Boxplot(cook)

daux = df[-c(1290,2757,55),]

mbest = glm(formula = target ~ poly(n.experience, 2) + relevent_experience + 
    enrolled_university + education_level + company_size + last_new_job + 
    training_hours + f.city_development_index, family = binomial, 
    data = daux)

influencePlot(mbest)
cook = cooks.distance(mbest)
Boxplot(cook)

```

### Model Performance Evaluation

ROC Curve:
```{r}
library(pROC)
prob=predict(mbest, type=c("response"))
daux$prob=prob
g = roc(target ~ prob, data = daux)
plot(g)
```

Area under the ROC Curve:
```{r}
auc(daux$target, prob)
```
Confusion matrix on working set
```{r}
prob = predict(mbest, newdata = daux, type = "response")
prob = ifelse(prob<0.5,0,1)
confusionMatrix(data = as.factor(prob), reference = daux$target)
```

Confusion matrix on the test set. First the same transformations that have been done during the modelling steps have to be applied to the test set 
```{r}
test = select(test, -c("city", "enrollee_id", "imputed"))

test = test %>%
  mutate(across(where(is.factor), ~ as.character(.))) %>%
  mutate(n.experience = case_when(experience == "<1" ~ "0",
                                experience == ">20" ~ "25",
                                TRUE ~ experience)) %>%
  mutate(n.experience = as.integer(n.experience)) %>%
  mutate(across(where(is.character), ~ as.factor(.))) %>%
  select(., -c("experience"))

test$f.city_development_index = as.ordered(cut2(test$city_development_index, cuts = c(0.691, 0.878, 0.920, 0.921)))
table(test$f.city_development_index)
table(df$f.city_development_index)
levels(test$f.city_development_index) <- c('[0.448,0.691)', '[0.691,0.878)', '[0.878,0.920)','0.920', '[0.921,0.949]')
test = select(test, -c("city_development_index"))
```



```{r}
prob = predict(mbest, newdata = test, type = "response")
test$prob = ifelse(prob<0.5,0,1)
confusionMatrix(data = as.factor(test$prob), reference = test$target)
```

